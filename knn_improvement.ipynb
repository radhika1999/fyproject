{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNBPdCUwwTEszMDvwQsyLep"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOjQS3wwxl_L","executionInfo":{"status":"ok","timestamp":1620458306934,"user_tz":-330,"elapsed":31314,"user":{"displayName":"Radhika Jain","photoUrl":"https://lh4.googleusercontent.com/-uM8ZGgVj4Vo/AAAAAAAAAAI/AAAAAAAAESc/NwQvnubo2Vo/s64/photo.jpg","userId":"12725112168480234392"}},"outputId":"c9bb14c1-da14-49b8-840a-44744bc40b6c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wiCmpB_exuz6","executionInfo":{"status":"ok","timestamp":1620463761531,"user_tz":-330,"elapsed":2913996,"user":{"displayName":"Radhika Jain","photoUrl":"https://lh4.googleusercontent.com/-uM8ZGgVj4Vo/AAAAAAAAAAI/AAAAAAAAESc/NwQvnubo2Vo/s64/photo.jpg","userId":"12725112168480234392"}},"outputId":"6e74f6ab-a42d-453b-fd74-ffd5c7c0b2e9"},"source":["import os\n","import pandas as pd\n","from scipy.sparse import csr_matrix\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from surprise import Dataset, Reader\n","from surprise import KNNBasic, BaselineOnly\n","from surprise.model_selection import cross_validate\n","from surprise.model_selection import KFold\n","from collections import defaultdict\n","\n","def precision_recall_at_k(predictions, k=10, threshold=3.5):\n","    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n","\n","    # First map the predictions to each user.\n","    user_est_true = defaultdict(list)\n","    for uid, _, true_r, est, _ in predictions:\n","        user_est_true[uid].append((est, true_r))\n","\n","    precisions = dict()\n","    recalls = dict()\n","    for uid, user_ratings in user_est_true.items():\n","\n","        # Sort user ratings by estimated value\n","        user_ratings.sort(key=lambda x: x[0], reverse=True)\n","\n","        # Number of relevant items\n","        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n","\n","        # Number of recommended items in top k\n","        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n","\n","        # Number of relevant and recommended items in top k\n","        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n","                              for (est, true_r) in user_ratings[:k])\n","\n","        # Precision@K: Proportion of recommended items that are relevant\n","        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n","\n","        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n","\n","        # Recall@K: Proportion of relevant items that are recommended\n","        # When n_rel is 0, Recall is undefined. We here set it to 0.\n","\n","        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n","\n","    return precisions, recalls\n","# configure file path\n","data_path = 'gdrive/MyDrive/movielens1m/'\n","movies_filename = 'movies.csv'\n","ratings_filename = 'ratings.csv'\n","# read data\n","df_movies = pd.read_csv(\n","    data_path + movies_filename,\n","    usecols=['movieId', 'title'],\n","    dtype={'movieId': 'int32', 'title': 'str'})\n","\n","df_ratings = pd.read_csv(\n","    (data_path + ratings_filename),\n","    usecols=['userId', 'movieId', 'rating'],\n","    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})\n","\n","# pivot ratings into movie features\n","df_movie_features = df_ratings.pivot(\n","    index='userId',\n","    columns='movieId',\n","    values='rating'\n",").fillna(0)\n","\n","\n","\n","df_movies_cnt = df_ratings.groupby('movieId') \\\n","       .agg({'userId':'size', 'rating':'mean'}) \\\n","       .rename(columns={'userId':'count','rating':'average'}) \\\n","       .reset_index()\n","\n","print(df_ratings)\n","print(df_movies_cnt)\n","movie_rating_thres = 10\n","\n","df_movies_cnt = df_movies_cnt.sort_values(by=['count']) \n","popular_movies = df_movies_cnt.head(movie_rating_thres)\n","print(popular_movies)\n","\n","movie_list = popular_movies['movieId'].tolist()\n","print(movie_list)\n","\n","\n","df_users_cnt = df_ratings.groupby('userId') \\\n","       .agg({'movieId':'size', 'rating':'mean'}) \\\n","       .rename(columns={'movieId':'count','rating':'average'}) \\\n","       .reset_index()\n","\n","print(df_users_cnt)\n","user_rating_thres = 30\n","\n","users_below_threshold = df_users_cnt[(df_users_cnt['count'] < user_rating_thres)]  \n","print(\"ans=\", len(users_below_threshold))\n","print(users_below_threshold)\n","\n","user_list = users_below_threshold['userId'].tolist()\n","print(user_list)\n","\n","print(df_movie_features)\n","\n","for u in user_list:\n","\tfor i in movie_list:\n","\t\tif df_ratings[(df_ratings.userId == u) & (df_ratings.movieId == i)].empty:\n","\t\t\tr = popular_movies.loc[popular_movies.movieId == i, 'average'].iloc[0]\n","\t\t\tnew_row = pd.Series({'userId': u, 'movieId': i, 'rating': r})\n","\t\t\tdf_ratings = df_ratings.append(new_row, ignore_index=True)\n","\n","print(df_ratings)\n","# users_filter = df_ratings.userId.isin(users_below_threshold).values\n","\n","reader = Reader(rating_scale=(1, 5))\n","\n","# The columns must correspond to user id, item id and ratings (in that order).\n","data = Dataset.load_from_df(df_ratings[['userId', 'movieId', 'rating']], reader)\n","\n","sim_options = {'name': 'cosine',\n","               'user_based': True  # compute  similarities between users\n","               }\n","algo = KNNBasic(sim_options=sim_options)\n","\n","cross_validate(algo, data, measures=['MAE','MSE','RMSE'], cv=5, verbose=True)\n","\n","kf = KFold(n_splits=5)\n","\n","for trainset, testset in kf.split(data):\n","    algo.fit(trainset)\n","    predictions = algo.test(testset)\n","    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n","\n","    # Precision and recall can then be averaged over all users\n","    print('Precision = ', sum(prec for prec in precisions.values()) / len(precisions))\n","    print('Recall = ', sum(rec for rec in recalls.values()) / len(recalls))\n","\n","# predicting ratings\n","# error = 0\n","# for i in mat_movie_features_test:\n","#     print(i)\n","#     distances, indices = model_knn.kneighbors(i,n_neighbors=6)\n","#     print(indices)\n","#     val = 0\n","#     for j in indices:\n","#         print(mat_movie_features[j])\n","#         val += mat_movie_features[j]\n","#     val /= 6\n","#     error += (val - i[1])*(val - i[1])\n","\n","\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["         userId  movieId  rating\n","0             1        2     3.5\n","1             1       29     3.5\n","2             1       32     3.5\n","3             1       47     3.5\n","4             1       50     3.5\n","...         ...      ...     ...\n","1048570    7120      168     5.0\n","1048571    7120      253     4.0\n","1048572    7120      260     5.0\n","1048573    7120      261     4.0\n","1048574    7120      266     3.5\n","\n","[1048575 rows x 3 columns]\n","       movieId  count   average\n","0            1   2569  3.959323\n","1            2   1155  3.268398\n","2            3    685  3.186861\n","3            4    138  3.000000\n","4            5    657  3.143836\n","...        ...    ...       ...\n","14021   130073      1  2.500000\n","14022   130219      1  4.500000\n","14023   130462      1  4.000000\n","14024   130490      2  2.250000\n","14025   130642      1  3.000000\n","\n","[14026 rows x 3 columns]\n","       movieId  count  average\n","14025   130642      1      3.0\n","12141    85312      1      2.5\n","12140    85307      1      3.5\n","12139    85305      1      0.5\n","5259      5547      1      2.0\n","12137    85278      1      3.5\n","9260     42987      1      4.5\n","12136    85268      1      2.0\n","9263     43248      1      1.0\n","9259     42973      1      3.5\n","[130642, 85312, 85307, 85305, 5547, 85278, 42987, 85268, 43248, 42973]\n","      userId  count   average\n","0          1    175  3.742857\n","1          2     61  4.000000\n","2          3    187  4.122994\n","3          4     28  3.571429\n","4          5     66  4.272727\n","...      ...    ...       ...\n","7115    7116    232  3.797414\n","7116    7117    188  3.936170\n","7117    7118     40  4.075000\n","7118    7119     50  3.740000\n","7119    7120     20  4.125000\n","\n","[7120 rows x 3 columns]\n","ans= 1334\n","      userId  count   average\n","3          4     28  3.571429\n","5          6     24  3.750000\n","16        17     26  4.038462\n","19        20     28  3.428571\n","35        36     20  2.800000\n","...      ...    ...       ...\n","7094    7095     24  3.833333\n","7097    7098     20  0.600000\n","7102    7103     28  4.214286\n","7111    7112     20  3.575000\n","7119    7120     20  4.125000\n","\n","[1334 rows x 3 columns]\n","[4, 6, 17, 20, 36, 37, 39, 52, 57, 59, 62, 79, 80, 81, 94, 95, 105, 111, 113, 123, 145, 146, 149, 150, 159, 161, 166, 171, 173, 174, 176, 177, 179, 180, 185, 187, 191, 193, 194, 197, 210, 214, 217, 224, 226, 227, 231, 243, 250, 257, 261, 268, 274, 276, 287, 291, 293, 296, 297, 300, 305, 319, 322, 325, 326, 327, 328, 329, 341, 345, 355, 362, 371, 392, 393, 396, 403, 404, 405, 408, 410, 420, 434, 437, 450, 454, 460, 464, 470, 480, 493, 495, 501, 502, 511, 513, 519, 522, 524, 527, 528, 529, 533, 538, 541, 542, 547, 550, 556, 566, 589, 597, 608, 613, 615, 616, 618, 624, 625, 639, 641, 644, 655, 668, 679, 681, 684, 687, 698, 701, 708, 712, 716, 719, 720, 723, 728, 730, 743, 746, 747, 751, 752, 759, 762, 764, 767, 780, 800, 803, 805, 813, 825, 826, 830, 832, 835, 836, 837, 842, 849, 850, 855, 859, 861, 862, 867, 874, 876, 880, 884, 904, 921, 922, 931, 944, 946, 958, 963, 966, 976, 991, 992, 999, 1004, 1005, 1008, 1009, 1013, 1029, 1033, 1043, 1054, 1059, 1064, 1066, 1067, 1069, 1075, 1077, 1079, 1097, 1109, 1110, 1112, 1124, 1132, 1137, 1138, 1142, 1151, 1156, 1167, 1180, 1182, 1189, 1193, 1194, 1201, 1203, 1204, 1205, 1214, 1215, 1229, 1231, 1241, 1253, 1255, 1273, 1275, 1286, 1289, 1292, 1293, 1303, 1314, 1319, 1325, 1332, 1333, 1336, 1337, 1342, 1346, 1354, 1355, 1366, 1379, 1394, 1397, 1405, 1408, 1410, 1414, 1425, 1428, 1432, 1434, 1438, 1445, 1447, 1448, 1461, 1462, 1464, 1467, 1485, 1490, 1493, 1497, 1517, 1522, 1527, 1531, 1534, 1536, 1541, 1549, 1558, 1561, 1576, 1578, 1583, 1585, 1594, 1596, 1597, 1598, 1605, 1611, 1613, 1618, 1631, 1642, 1646, 1647, 1648, 1651, 1654, 1655, 1656, 1663, 1664, 1679, 1680, 1683, 1691, 1695, 1701, 1709, 1712, 1727, 1739, 1740, 1742, 1754, 1762, 1765, 1766, 1769, 1773, 1781, 1785, 1787, 1788, 1793, 1794, 1795, 1796, 1797, 1801, 1802, 1805, 1818, 1821, 1822, 1846, 1852, 1853, 1856, 1871, 1872, 1875, 1878, 1884, 1895, 1898, 1900, 1917, 1923, 1926, 1933, 1934, 1938, 1940, 1943, 1944, 1950, 1962, 1974, 1978, 1981, 1990, 1991, 1995, 1998, 2016, 2020, 2023, 2025, 2027, 2028, 2039, 2041, 2049, 2055, 2059, 2074, 2077, 2079, 2086, 2091, 2096, 2097, 2102, 2103, 2105, 2106, 2110, 2112, 2115, 2125, 2132, 2142, 2146, 2148, 2154, 2173, 2182, 2189, 2190, 2207, 2216, 2218, 2223, 2237, 2249, 2251, 2264, 2266, 2271, 2277, 2279, 2282, 2287, 2290, 2294, 2297, 2303, 2304, 2305, 2312, 2316, 2318, 2319, 2326, 2329, 2340, 2342, 2346, 2348, 2359, 2364, 2369, 2375, 2377, 2379, 2385, 2390, 2401, 2407, 2411, 2414, 2415, 2421, 2425, 2434, 2439, 2442, 2445, 2446, 2449, 2450, 2453, 2457, 2460, 2463, 2467, 2471, 2473, 2479, 2489, 2490, 2491, 2495, 2499, 2501, 2504, 2510, 2522, 2526, 2530, 2532, 2535, 2541, 2547, 2548, 2559, 2566, 2569, 2572, 2579, 2587, 2588, 2592, 2597, 2613, 2615, 2619, 2622, 2624, 2628, 2632, 2635, 2642, 2652, 2667, 2673, 2674, 2679, 2685, 2687, 2688, 2700, 2701, 2704, 2705, 2708, 2714, 2716, 2717, 2721, 2730, 2738, 2746, 2747, 2763, 2779, 2796, 2797, 2798, 2799, 2800, 2815, 2817, 2820, 2824, 2827, 2828, 2831, 2832, 2846, 2850, 2853, 2861, 2869, 2870, 2873, 2878, 2884, 2888, 2896, 2901, 2904, 2911, 2917, 2929, 2936, 2938, 2939, 2940, 2944, 2953, 2954, 2956, 2960, 2968, 2975, 2976, 2977, 2981, 2986, 2989, 2999, 3003, 3005, 3006, 3009, 3012, 3023, 3030, 3034, 3044, 3046, 3066, 3067, 3082, 3084, 3090, 3096, 3098, 3104, 3105, 3118, 3119, 3120, 3121, 3123, 3129, 3130, 3134, 3137, 3140, 3147, 3154, 3156, 3158, 3164, 3168, 3169, 3175, 3180, 3188, 3190, 3193, 3209, 3220, 3229, 3232, 3247, 3248, 3261, 3270, 3276, 3292, 3299, 3303, 3304, 3305, 3308, 3314, 3322, 3323, 3332, 3336, 3337, 3339, 3342, 3346, 3349, 3350, 3354, 3355, 3357, 3362, 3370, 3372, 3375, 3377, 3378, 3380, 3414, 3420, 3425, 3434, 3435, 3436, 3438, 3442, 3449, 3454, 3462, 3473, 3475, 3477, 3489, 3493, 3500, 3501, 3507, 3519, 3522, 3525, 3541, 3544, 3555, 3558, 3561, 3564, 3574, 3581, 3584, 3590, 3599, 3620, 3622, 3626, 3627, 3636, 3637, 3638, 3647, 3661, 3666, 3668, 3669, 3675, 3677, 3687, 3689, 3691, 3696, 3707, 3709, 3716, 3721, 3725, 3730, 3732, 3747, 3756, 3769, 3770, 3781, 3787, 3789, 3790, 3798, 3801, 3810, 3814, 3820, 3823, 3824, 3825, 3829, 3831, 3837, 3838, 3839, 3840, 3841, 3853, 3857, 3866, 3873, 3884, 3889, 3893, 3900, 3902, 3908, 3909, 3913, 3914, 3918, 3923, 3929, 3931, 3937, 3945, 3946, 3947, 3949, 3950, 3952, 3954, 3959, 3972, 3974, 3975, 3979, 4001, 4013, 4019, 4025, 4035, 4041, 4043, 4049, 4050, 4058, 4069, 4070, 4086, 4092, 4093, 4095, 4099, 4104, 4110, 4121, 4122, 4131, 4134, 4139, 4143, 4148, 4152, 4154, 4166, 4179, 4182, 4190, 4205, 4206, 4212, 4218, 4231, 4232, 4236, 4239, 4240, 4245, 4247, 4259, 4263, 4265, 4269, 4271, 4273, 4278, 4280, 4288, 4294, 4298, 4299, 4300, 4303, 4304, 4306, 4312, 4315, 4317, 4321, 4322, 4335, 4336, 4339, 4346, 4354, 4356, 4383, 4386, 4387, 4407, 4408, 4412, 4414, 4422, 4427, 4440, 4443, 4445, 4447, 4454, 4456, 4460, 4473, 4487, 4491, 4502, 4503, 4506, 4512, 4535, 4543, 4552, 4559, 4560, 4561, 4579, 4582, 4593, 4596, 4602, 4608, 4609, 4610, 4611, 4616, 4621, 4623, 4632, 4633, 4645, 4647, 4653, 4667, 4676, 4681, 4683, 4690, 4692, 4703, 4707, 4715, 4717, 4724, 4727, 4732, 4741, 4747, 4751, 4753, 4754, 4757, 4764, 4773, 4782, 4803, 4806, 4813, 4816, 4820, 4824, 4830, 4837, 4849, 4863, 4867, 4874, 4881, 4883, 4887, 4890, 4891, 4897, 4899, 4905, 4908, 4911, 4913, 4925, 4926, 4939, 4940, 4942, 4944, 4946, 4947, 4957, 4966, 4984, 4987, 4990, 4993, 5006, 5013, 5020, 5024, 5028, 5029, 5039, 5042, 5050, 5051, 5052, 5053, 5064, 5085, 5089, 5093, 5111, 5117, 5127, 5129, 5139, 5147, 5151, 5158, 5160, 5163, 5165, 5170, 5174, 5184, 5194, 5202, 5205, 5208, 5211, 5212, 5213, 5217, 5218, 5222, 5223, 5229, 5246, 5249, 5250, 5258, 5263, 5268, 5280, 5283, 5294, 5301, 5307, 5316, 5317, 5318, 5320, 5321, 5327, 5339, 5343, 5344, 5357, 5358, 5361, 5363, 5369, 5381, 5383, 5387, 5389, 5394, 5398, 5405, 5413, 5421, 5426, 5435, 5436, 5445, 5459, 5460, 5461, 5463, 5469, 5474, 5484, 5492, 5493, 5502, 5505, 5519, 5533, 5535, 5541, 5549, 5551, 5557, 5560, 5562, 5566, 5568, 5579, 5581, 5583, 5586, 5587, 5588, 5610, 5617, 5619, 5625, 5632, 5634, 5641, 5645, 5649, 5652, 5659, 5660, 5666, 5667, 5670, 5678, 5687, 5688, 5690, 5701, 5702, 5713, 5721, 5724, 5728, 5733, 5736, 5744, 5746, 5747, 5750, 5756, 5761, 5769, 5781, 5785, 5802, 5804, 5811, 5821, 5859, 5860, 5869, 5874, 5880, 5891, 5901, 5905, 5909, 5910, 5913, 5919, 5920, 5923, 5931, 5937, 5939, 5947, 5948, 5953, 5955, 5961, 5975, 5977, 5985, 5987, 5988, 5989, 5992, 5993, 5996, 5998, 6001, 6006, 6010, 6011, 6019, 6022, 6037, 6058, 6063, 6066, 6076, 6087, 6094, 6107, 6121, 6130, 6138, 6144, 6149, 6153, 6154, 6161, 6163, 6176, 6185, 6186, 6189, 6192, 6195, 6205, 6210, 6214, 6215, 6216, 6222, 6227, 6229, 6240, 6248, 6251, 6261, 6265, 6270, 6278, 6281, 6285, 6287, 6292, 6293, 6295, 6305, 6307, 6315, 6322, 6323, 6327, 6334, 6339, 6343, 6347, 6350, 6353, 6354, 6370, 6376, 6384, 6396, 6408, 6413, 6426, 6427, 6430, 6434, 6435, 6437, 6439, 6441, 6458, 6466, 6474, 6483, 6487, 6488, 6491, 6492, 6499, 6502, 6503, 6504, 6505, 6507, 6515, 6517, 6518, 6521, 6526, 6536, 6537, 6541, 6542, 6547, 6555, 6556, 6557, 6563, 6564, 6567, 6574, 6577, 6579, 6583, 6584, 6588, 6589, 6591, 6592, 6598, 6599, 6601, 6612, 6615, 6619, 6629, 6631, 6642, 6648, 6649, 6653, 6654, 6659, 6665, 6668, 6671, 6678, 6681, 6682, 6683, 6693, 6697, 6698, 6703, 6705, 6706, 6717, 6724, 6740, 6742, 6746, 6756, 6758, 6759, 6779, 6780, 6782, 6785, 6786, 6790, 6807, 6808, 6809, 6818, 6821, 6826, 6830, 6831, 6835, 6855, 6857, 6858, 6859, 6865, 6866, 6869, 6871, 6872, 6876, 6877, 6894, 6895, 6896, 6900, 6902, 6907, 6909, 6914, 6923, 6926, 6935, 6938, 6941, 6942, 6946, 6949, 6954, 6955, 6974, 6975, 6981, 6982, 6984, 6986, 6987, 6990, 6991, 6992, 6999, 7001, 7004, 7009, 7014, 7023, 7027, 7034, 7039, 7043, 7070, 7072, 7073, 7076, 7082, 7090, 7095, 7098, 7103, 7112, 7120]\n","movieId  1       2       3       4       ...  130219  130462  130490  130642\n","userId                                   ...                                \n","1           0.0     3.5     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","2           0.0     0.0     4.0     0.0  ...     0.0     0.0     0.0     0.0\n","3           4.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","4           0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","5           0.0     3.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","...         ...     ...     ...     ...  ...     ...     ...     ...     ...\n","7116        4.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","7117        4.0     0.0     4.0     0.0  ...     0.0     0.0     0.0     0.0\n","7118        0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","7119        5.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","7120        4.5     4.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n","\n","[7120 rows x 14026 columns]\n","         userId  movieId  rating\n","0           1.0      2.0     3.5\n","1           1.0     29.0     3.5\n","2           1.0     32.0     3.5\n","3           1.0     47.0     3.5\n","4           1.0     50.0     3.5\n","...         ...      ...     ...\n","1061910  7120.0  85278.0     3.5\n","1061911  7120.0  42987.0     4.5\n","1061912  7120.0  85268.0     2.0\n","1061913  7120.0  43248.0     1.0\n","1061914  7120.0  42973.0     3.5\n","\n","[1061915 rows x 3 columns]\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Evaluating MAE, MSE, RMSE of algorithm KNNBasic on 5 split(s).\n","\n","                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n","MAE (testset)     0.7226  0.7231  0.7207  0.7216  0.7228  0.7222  0.0009  \n","MSE (testset)     0.8920  0.8940  0.8920  0.8949  0.8949  0.8936  0.0013  \n","RMSE (testset)    0.9444  0.9455  0.9445  0.9460  0.9460  0.9453  0.0007  \n","Fit time          82.00   87.10   83.48   82.16   83.50   83.65   1.84    \n","Test time         179.01  170.82  179.64  178.05  176.50  176.80  3.17    \n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Precision =  0.6745890122242569\n","Recall =  0.2651822626295349\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Precision =  0.6695209328463105\n","Recall =  0.2578407046701555\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Precision =  0.6720864353607756\n","Recall =  0.2623391375339492\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Precision =  0.6643271977893348\n","Recall =  0.25586250545858985\n","Computing the cosine similarity matrix...\n","Done computing similarity matrix.\n","Precision =  0.6632288885766515\n","Recall =  0.2593967920412341\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rv2wJBwG1_b1","executionInfo":{"status":"ok","timestamp":1620458390255,"user_tz":-330,"elapsed":36990,"user":{"displayName":"Radhika Jain","photoUrl":"https://lh4.googleusercontent.com/-uM8ZGgVj4Vo/AAAAAAAAAAI/AAAAAAAAESc/NwQvnubo2Vo/s64/photo.jpg","userId":"12725112168480234392"}},"outputId":"fe524b48-1239-43b0-86a4-06195bc9ac1a"},"source":["!pip install surprise"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting surprise\n","  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n","Collecting scikit-surprise\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n","\u001b[K     |████████████████████████████████| 11.8MB 298kB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n","Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617575 sha256=2b9506cb8a0f22c74d5357faf0f592fca5ae5fe08069113e9baf506ebe46f4df\n","  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise, surprise\n","Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"],"name":"stdout"}]}]}